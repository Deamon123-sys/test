import streamlit as st
from sentence_transformers import SentenceTransformer
import pandas as pd
from search import vector_search, hyde_search
from constant import USER, ASSISTANT, ONLINE_LLM
import chromadb
import json

# Hi·ªÉn th·ªã ti√™u ƒë·ªÅ v√† gi·ªõi thi·ªáu c·ªßa chatbot UIT
st.markdown(
    """
    <h1 style='display: flex; align-items: center;'>
        <img src="https://tuyensinh.uit.edu.vn/sites/default/files/uploads/images/uit_footer.png" width="50" style='margin-right: 10px'>
        UIT Admissions Chatbot üéì
    </h1>
    """,
    unsafe_allow_html=True
)
st.markdown("Welcome to the UIT Admissions Chatbot!‚ùì‚ùì‚ùì Discover all the information you need about admissions, üìöprograms, üí∏scholarships, üåüStudent Life at UIT and more with us.")

# H√†m t·∫£i tr·∫°ng th√°i phi√™n l√†m vi·ªác t·ª´ m·ªôt t·ªáp JSON
def load_session_state(file_path="session_state.json"):
    try:
        with open(file_path, "r") as file:
            session_data = json.load(file)  # ƒê·ªçc d·ªØ li·ªáu t·ª´ t·ªáp JSON
        for key, value in session_data.items():
            st.session_state[key] = value  # C·∫≠p nh·∫≠t tr·∫°ng th√°i phi√™n l√†m vi·ªác v·ªõi d·ªØ li·ªáu t·ª´ t·ªáp
        # st.success("Session state loaded successfully!")
    except FileNotFoundError:
        st.error("Session state file not found.")  # Hi·ªÉn th·ªã l·ªói n·∫øu kh√¥ng t√¨m th·∫•y t·ªáp
    except json.JSONDecodeError:
        st.error("Error decoding session state file.")  # Hi·ªÉn th·ªã l·ªói n·∫øu c√≥ v·∫•n ƒë·ªÅ khi ƒë·ªçc t·ªáp JSON

# Thi·∫øt l·∫≠p t√πy ch·ªçn t√¨m ki·∫øm m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a ƒë∆∞·ª£c ƒë·∫∑t trong session
if "search_option" not in st.session_state:
    st.session_state.search_option = "Vector Search"

# Hi·ªÉn th·ªã t√™n c·ªßa t·∫≠p d·ªØ li·ªáu (collection) n·∫øu ƒë√£ c√≥ s·∫µn
if "collection" not in st.session_state:
    load_session_state(file_path="pages/session_state.json")  # T·∫£i tr·∫°ng th√°i phi√™n l√†m vi·ªác t·ª´ t·ªáp JSON

# Kh·ªüi t·∫°o kh√°ch h√†ng Chroma n·∫øu ch∆∞a c√≥
if "client" not in st.session_state:
    st.session_state.client = chromadb.PersistentClient("db")  # T·∫°o k·∫øt n·ªëi v·ªõi c∆° s·ªü d·ªØ li·ªáu Chroma
    if "random_collection_name" in st.session_state:
        st.session_state.collection = st.session_state.client.get_collection(
            st.session_state.random_collection_name  # L·∫•y collection d·ª±a tr√™n t√™n ƒë∆∞·ª£c l∆∞u trong session
        )

# Kh·ªüi t·∫°o m√¥ h√¨nh embedding n·∫øu ch∆∞a c√≥
if "embedding_model_name" in st.session_state and "embedding_model" not in st.session_state:
    st.session_state.embedding_model = SentenceTransformer(
        st.session_state.embedding_model_name  # T·∫£i m√¥ h√¨nh SentenceTransformer d·ª±a tr√™n t√™n m√¥ h√¨nh
    )

# Kh·ªüi t·∫°o c·ªôt m·∫∑c ƒë·ªãnh cho c√¢u tr·∫£ l·ªùi
if "columns_to_answer" not in st.session_state:
    st.session_state.columns_to_answer = ["chunk", "question", "answer"]

# Kh·ªüi t·∫°o l·ªãch s·ª≠ h·ªôi tho·∫°i trong session n·∫øu ch∆∞a c√≥
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i b·∫±ng giao di·ªán tr√≤ chuy·ªán
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])  # Hi·ªÉn th·ªã n·ªôi dung t·ª´ng tin nh·∫Øn trong l·ªãch s·ª≠ h·ªôi tho·∫°i

# X·ª≠ l√Ω v√† hi·ªÉn th·ªã c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
if prompt := st.chat_input("What is up?"):
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i
    st.session_state.chat_history.append({"role": USER, "content": prompt})

    # Hi·ªÉn th·ªã tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng trong giao di·ªán tr√≤ chuy·ªán
    with st.chat_message(USER):
        st.markdown(prompt)

    # X·ª≠ l√Ω v√† c·∫£i thi·ªán prompt c·ªßa ng∆∞·ªùi d√πng
    if st.session_state.collection is not None:
        metadatas, retrieved_data = [], ""
        if "columns_to_answer" in st.session_state:
            columns_to_answer = st.session_state.columns_to_answer
            search_option = st.session_state.search_option

            # Th·ª±c hi·ªán t√¨m ki·∫øm d·ª±a tr√™n t√πy ch·ªçn t√¨m ki·∫øm hi·ªán t·∫°i
            if search_option == "Vector Search":
                metadatas, retrieved_data = vector_search(
                    st.session_state.embedding_model,
                    prompt,
                    st.session_state.collection,
                    columns_to_answer,
                    st.session_state.number_docs_retrieval
                )

            elif search_option == "Hyde Search":
                model = st.session_state.llm_model
                metadatas, retrieved_data = hyde_search(
                    model,
                    st.session_state.embedding_model,
                    prompt,
                    st.session_state.collection,
                    columns_to_answer,
                    st.session_state.number_docs_retrieval,
                    num_samples=1
                )

            # T·∫°o prompt n√¢ng cao v√† sinh c√¢u tr·∫£ l·ªùi t·ª´ m√¥ h√¨nh ng√¥n ng·ªØ
            if metadatas:
                # Th√™m ng·ªØ c·∫£nh chi ti·∫øt v√†o prompt n√¢ng cao
                enhanced_prompt = (
                f'The user prompt is: "{prompt}". '
                "You are a chatbot designed to answer questions related to admissions at UIT (University of Information Technology). "
                "Please respond in a friendly and helpful manner, providing accurate and detailed information about admissions, "
                "scholarships, programs, and student life at UIT. Use the following retrieved data to craft your response:\n"
                f"{retrieved_data}")
                response = st.session_state.llm_model.generate_content(enhanced_prompt)

                # C·∫≠p nh·∫≠t l·ªãch s·ª≠ h·ªôi tho·∫°i
                st.markdown(response)
                st.session_state.chat_history.append({"role": ASSISTANT, "content": response})
            else:
                st.warning("No data to enhance the prompt.")  # C·∫£nh b√°o n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ h·ªó tr·ª£ t·∫°o c√¢u tr·∫£ l·ªùi
        else:
            st.warning("Select columns to answer from.")  # C·∫£nh b√°o n·∫øu ch∆∞a ch·ªçn c·ªôt ƒë·ªÉ tr·∫£ l·ªùi
    else:
        st.error("No collection found. Upload data and save it first.")  # Hi·ªÉn th·ªã l·ªói n·∫øu ch∆∞a t·∫£i t·∫≠p d·ªØ li·ªáu
